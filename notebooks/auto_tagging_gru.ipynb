{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-tagging system based on LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils.s3_class import S3Functions\n",
    "\n",
    "s3_funcs = S3Functions(bucket_name='jdgallegoq-autotagging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "questions_df = pd.read_csv(\n",
    "    s3_funcs.read_object(key='Questions.csv'),\n",
    "    encoding='latin-1',\n",
    "    encoding_errors='ignore'\n",
    ")\n",
    "tags_df = pd.read_csv(s3_funcs.read_object('Tags.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2010-07-19T19:14:44Z</td>\n",
       "      <td>272</td>\n",
       "      <td>The Two Cultures: statistics vs. machine learn...</td>\n",
       "      <td>&lt;p&gt;Last year, I read a blog post from &lt;a href=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2010-07-19T19:24:36Z</td>\n",
       "      <td>4</td>\n",
       "      <td>Forecasting demographic census</td>\n",
       "      <td>&lt;p&gt;What are some of the ways to forecast demog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2010-07-19T19:25:39Z</td>\n",
       "      <td>208</td>\n",
       "      <td>Bayesian and frequentist reasoning in plain En...</td>\n",
       "      <td>&lt;p&gt;How would you describe in plain English the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2010-07-19T19:28:44Z</td>\n",
       "      <td>138</td>\n",
       "      <td>What is the meaning of p values and t values i...</td>\n",
       "      <td>&lt;p&gt;After taking a statistics course and then t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2010-07-19T19:31:47Z</td>\n",
       "      <td>58</td>\n",
       "      <td>Examples for teaching: Correlation does not me...</td>\n",
       "      <td>&lt;p&gt;There is an old saying: \"Correlation does n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  OwnerUserId          CreationDate  Score  \\\n",
       "0   6          5.0  2010-07-19T19:14:44Z    272   \n",
       "1  21         59.0  2010-07-19T19:24:36Z      4   \n",
       "2  22         66.0  2010-07-19T19:25:39Z    208   \n",
       "3  31         13.0  2010-07-19T19:28:44Z    138   \n",
       "4  36          8.0  2010-07-19T19:31:47Z     58   \n",
       "\n",
       "                                               Title  \\\n",
       "0  The Two Cultures: statistics vs. machine learn...   \n",
       "1                     Forecasting demographic census   \n",
       "2  Bayesian and frequentist reasoning in plain En...   \n",
       "3  What is the meaning of p values and t values i...   \n",
       "4  Examples for teaching: Correlation does not me...   \n",
       "\n",
       "                                                Body  \n",
       "0  <p>Last year, I read a blog post from <a href=...  \n",
       "1  <p>What are some of the ways to forecast demog...  \n",
       "2  <p>How would you describe in plain English the...  \n",
       "3  <p>After taking a statistics course and then t...  \n",
       "4  <p>There is an old saying: \"Correlation does n...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bayesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>elicitation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>distributions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>normality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id            Tag\n",
       "0   1       bayesian\n",
       "1   1          prior\n",
       "2   1    elicitation\n",
       "3   2  distributions\n",
       "4   2      normality"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(questions_df.head())\n",
    "display(tags_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Cleaning for Question Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(text:str=None):\n",
    "    # remove html tags\n",
    "    text = BeautifulSoup(text).get_text()\n",
    "    # converto to lower\n",
    "    text = text.lower()\n",
    "    # fetch only alphabetic characters\n",
    "    text = re.sub(r'[^a-z]', ' ', text)\n",
    "    # split into tokens to remove whitespaces\n",
    "    tokens = text.split()\n",
    "\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean text o question df\n",
    "questions_df['cleaned_text'] = questions_df['Body'].apply(cleaner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r                       13236\n",
       "regression              10959\n",
       "machine-learning         6089\n",
       "time-series              5559\n",
       "probability              4217\n",
       "                        ...  \n",
       "fmincon                     1\n",
       "doc2vec                     1\n",
       "sympy                       1\n",
       "adversarial-boosting        1\n",
       "corpus-linguistics          1\n",
       "Name: Tag, Length: 1315, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_df['Tag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[bayesian, prior, elicitation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[distributions, normality]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[software, opensource]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[distributions, statisticalsignificance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>[machinelearning]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                      tags\n",
       "0   1            [bayesian, prior, elicitation]\n",
       "1   2                [distributions, normality]\n",
       "2   3                    [software, opensource]\n",
       "3   4  [distributions, statisticalsignificance]\n",
       "4   6                         [machinelearning]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group tags by id\n",
    "tags_df['Tag'] = tags_df['Tag'].apply(lambda x: re.sub('-', '', x))\n",
    "tags_df = tags_df.groupby('Id').apply(lambda x: x['Tag'].values).reset_index(name='tags')\n",
    "tags_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Body</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;How should I elicit prior distributions fro...</td>\n",
       "      <td>how should i elicit prior distributions from e...</td>\n",
       "      <td>[bayesian, prior, elicitation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;p&gt;In many different statistical methods there...</td>\n",
       "      <td>in many different statistical methods there is...</td>\n",
       "      <td>[distributions, normality]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>&lt;p&gt;What are some valuable Statistical Analysis...</td>\n",
       "      <td>what are some valuable statistical analysis op...</td>\n",
       "      <td>[software, opensource]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;p&gt;I have two groups of data.  Each with a dif...</td>\n",
       "      <td>i have two groups of data each with a differen...</td>\n",
       "      <td>[distributions, statisticalsignificance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>&lt;p&gt;Last year, I read a blog post from &lt;a href=...</td>\n",
       "      <td>last year i read a blog post from brendan o co...</td>\n",
       "      <td>[machinelearning]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                               Body  \\\n",
       "0   1  <p>How should I elicit prior distributions fro...   \n",
       "1   2  <p>In many different statistical methods there...   \n",
       "2   3  <p>What are some valuable Statistical Analysis...   \n",
       "3   4  <p>I have two groups of data.  Each with a dif...   \n",
       "4   6  <p>Last year, I read a blog post from <a href=...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  how should i elicit prior distributions from e...   \n",
       "1  in many different statistical methods there is...   \n",
       "2  what are some valuable statistical analysis op...   \n",
       "3  i have two groups of data each with a differen...   \n",
       "4  last year i read a blog post from brendan o co...   \n",
       "\n",
       "                                       tags  \n",
       "0            [bayesian, prior, elicitation]  \n",
       "1                [distributions, normality]  \n",
       "2                    [software, opensource]  \n",
       "3  [distributions, statisticalsignificance]  \n",
       "4                         [machinelearning]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge with qiestions\n",
    "df = pd.merge(\n",
    "    tags_df,\n",
    "    questions_df,\n",
    "    on='Id',\n",
    "    how='inner'\n",
    ")[['Id', 'Body', 'cleaned_text', 'tags']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation\n",
    "Only use data for most frequent tags. Let's say top 10, top 20..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get a top n\n",
    "n = 10\n",
    "top_10 = Counter([v for row in df.tags.values for v in row]).most_common(n)\n",
    "# convert into a dict\n",
    "top_10 = dict(top_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get X and y based on those most common tags\n",
    "x = []\n",
    "y = []\n",
    "for i in range(df['tags'].shape[0]):\n",
    "    temp = []\n",
    "    for j in df['tags'][i]:\n",
    "        if j in top_10.keys():\n",
    "            temp.append(j)\n",
    "    \n",
    "    if (len(temp)>1):\n",
    "        x.append(df['cleaned_text'][i])\n",
    "        y.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11106, 11106)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11106, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer # create multilabel\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "y = mlb.fit_transform(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # split data\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    x,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprare tokenizer\n",
    "x_tokenizer = Tokenizer()\n",
    "x_tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25069"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many tokens do we have in our corpus\n",
    "len(x_tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12570\n"
     ]
    }
   ],
   "source": [
    "# if want to filter unknown tokens\n",
    "threshold = 3 # at least appears 3 times in all corpus\n",
    "c = 0\n",
    "for key, value in x_tokenizer.word_counts.items():\n",
    "    if value>=threshold:\n",
    "        c += 1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define again tokenizer with filtering\n",
    "x_tokenizer = Tokenizer(\n",
    "    num_words=c,\n",
    "    oov_token='unk' # define value for unknown tokens\n",
    ")\n",
    "x_tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad sequences: guarantee that all sequences are going to have\n",
    "# the same lenght; ex: define all texts to be 100 tokens lenght.\n",
    "max_len = 100\n",
    "\n",
    "X_train_seq = x_tokenizer.texts_to_sequences(X_train)\n",
    "X_val_seq = x_tokenizer.texts_to_sequences(X_val)\n",
    "\n",
    "# pad adding zeros\n",
    "X_train_seq = pad_sequences(X_train_seq, padding='post', maxlen=max_len)\n",
    "X_val_seq = pad_sequences(X_val_seq, padding='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    Embedding,\n",
    "    GRU,\n",
    "\n",
    ")\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vocabulary size\n",
    "x_voc_size = x_tokenizer.num_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 50)           628550    \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 128)               69120     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 715472 (2.73 MB)\n",
      "Trainable params: 715472 (2.73 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(x_voc_size, 50, input_shape=(max_len,), mask_zero=True))\n",
    "model.add(GRU(128,))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='sigmoid')) # 10 is the number of classes to predict\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='binary_crossentropy'\n",
    ")\n",
    "\n",
    "# model callbacks\n",
    "callbacks = ModelCheckpoint(\n",
    "    \"weights.best.hdf5\",\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.5253\n",
      "Epoch 1: val_loss improved from inf to 0.47843, saving model to weights.best.hdf5\n",
      "70/70 [==============================] - 10s 123ms/step - loss: 0.5253 - val_loss: 0.4784\n",
      "Epoch 2/10\n",
      " 1/70 [..............................] - ETA: 7s - loss: 0.4711"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - ETA: 0s - loss: 0.4763\n",
      "Epoch 2: val_loss improved from 0.47843 to 0.46887, saving model to weights.best.hdf5\n",
      "70/70 [==============================] - 9s 126ms/step - loss: 0.4763 - val_loss: 0.4689\n",
      "Epoch 3/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.4382\n",
      "Epoch 3: val_loss improved from 0.46887 to 0.41516, saving model to weights.best.hdf5\n",
      "70/70 [==============================] - 8s 120ms/step - loss: 0.4382 - val_loss: 0.4152\n",
      "Epoch 4/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.3959\n",
      "Epoch 4: val_loss improved from 0.41516 to 0.40564, saving model to weights.best.hdf5\n",
      "70/70 [==============================] - 8s 121ms/step - loss: 0.3959 - val_loss: 0.4056\n",
      "Epoch 5/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.3660\n",
      "Epoch 5: val_loss improved from 0.40564 to 0.39237, saving model to weights.best.hdf5\n",
      "70/70 [==============================] - 9s 122ms/step - loss: 0.3660 - val_loss: 0.3924\n",
      "Epoch 6/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.3186\n",
      "Epoch 6: val_loss improved from 0.39237 to 0.35978, saving model to weights.best.hdf5\n",
      "70/70 [==============================] - 8s 119ms/step - loss: 0.3186 - val_loss: 0.3598\n",
      "Epoch 7/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.2765\n",
      "Epoch 7: val_loss improved from 0.35978 to 0.34561, saving model to weights.best.hdf5\n",
      "70/70 [==============================] - 8s 120ms/step - loss: 0.2765 - val_loss: 0.3456\n",
      "Epoch 8/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.2425\n",
      "Epoch 8: val_loss improved from 0.34561 to 0.34543, saving model to weights.best.hdf5\n",
      "70/70 [==============================] - 9s 122ms/step - loss: 0.2425 - val_loss: 0.3454\n",
      "Epoch 9/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.2148\n",
      "Epoch 9: val_loss did not improve from 0.34543\n",
      "70/70 [==============================] - 9s 131ms/step - loss: 0.2148 - val_loss: 0.3508\n",
      "Epoch 10/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.1879\n",
      "Epoch 10: val_loss did not improve from 0.34543\n",
      "70/70 [==============================] - 9s 127ms/step - loss: 0.1879 - val_loss: 0.3700\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "model_history = model.fit(\n",
    "    X_train_seq,\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    validation_data=(X_val_seq, y_val),\n",
    "    callbacks=[callbacks]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 2s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.23657246, 0.17965588, 0.16786788, 0.39927116, 0.21967882,\n",
       "       0.18755539, 0.39806244, 0.47501236, 0.13913867, 0.02432637],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"weights.best.hdf5\")\n",
    "\n",
    "# predict\n",
    "pred_prob = model.predict(X_val_seq)\n",
    "pred_prob[0] # it displays 10 probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best threshold value\n",
    "thres = np.arange(0, 0.5, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert probas to classes based on a threshold value\n",
    "def classify(pred_prob, thres):\n",
    "    y_pred_seq = []\n",
    "    for i in pred_prob:\n",
    "        temp = []\n",
    "        for j in i:\n",
    "            if j>thres:\n",
    "                temp.append(1)\n",
    "            else:\n",
    "                temp.append(0)\n",
    "        y_pred_seq.append(temp)\n",
    "\n",
    "    return y_pred_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = []\n",
    "# convert to 1-d array\n",
    "y_true = np.array(y_val).ravel()\n",
    "for t in thres:\n",
    "    y_pred_seq = classify(pred_prob, t)\n",
    "    y_pred = np.array(y_pred_seq).ravel()\n",
    "    score.append(metrics.f1_score(y_true, y_pred))\n",
    "\n",
    "# find optimum\n",
    "opt = thres[score.index(max(score))]\n",
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90     17512\n",
      "           1       0.61      0.70      0.65      4708\n",
      "\n",
      "    accuracy                           0.84     22220\n",
      "   macro avg       0.76      0.79      0.78     22220\n",
      "weighted avg       0.85      0.84      0.85     22220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now based on optimum from above then get preds\n",
    "y_pred_seq = classify(pred_prob, opt)\n",
    "y_pred = np.array(y_pred_seq).ravel()\n",
    "print(metrics.classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>actual</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i would like to test if subjects are significa...</td>\n",
       "      <td>(hypothesistesting, logistic)</td>\n",
       "      <td>(logistic, regression)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>could somebody explain this difference just as...</td>\n",
       "      <td>(classification, machinelearning)</td>\n",
       "      <td>(regression, selfstudy)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lets say you want to create a random forest mo...</td>\n",
       "      <td>(classification, regression)</td>\n",
       "      <td>(classification, machinelearning)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am trying to estimate a logit regression mod...</td>\n",
       "      <td>(logistic, r, regression)</td>\n",
       "      <td>(logistic, regression)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i want to calculate the posterior distribution...</td>\n",
       "      <td>(distributions, selfstudy)</td>\n",
       "      <td>(distributions, probability, selfstudy)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i have a farm with years data about the area a...</td>\n",
       "      <td>(distributions, timeseries)</td>\n",
       "      <td>(machinelearning, r, regression)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>in the book of hosmer lemeshow it is stated in...</td>\n",
       "      <td>(logistic, regression)</td>\n",
       "      <td>(logistic, regression)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i find this counter intuitive first i chose ra...</td>\n",
       "      <td>(machinelearning, regression)</td>\n",
       "      <td>(classification, logistic, machinelearning, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i have a list of sites and a list of survival ...</td>\n",
       "      <td>(r, regression)</td>\n",
       "      <td>(probability, selfstudy)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i want to assess the effect of temperature on ...</td>\n",
       "      <td>(regression, timeseries)</td>\n",
       "      <td>(r, regression, timeseries)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  \\\n",
       "0  i would like to test if subjects are significa...   \n",
       "1  could somebody explain this difference just as...   \n",
       "2  lets say you want to create a random forest mo...   \n",
       "3  i am trying to estimate a logit regression mod...   \n",
       "4  i want to calculate the posterior distribution...   \n",
       "5  i have a farm with years data about the area a...   \n",
       "6  in the book of hosmer lemeshow it is stated in...   \n",
       "7  i find this counter intuitive first i chose ra...   \n",
       "8  i have a list of sites and a list of survival ...   \n",
       "9  i want to assess the effect of temperature on ...   \n",
       "\n",
       "                              actual  \\\n",
       "0      (hypothesistesting, logistic)   \n",
       "1  (classification, machinelearning)   \n",
       "2       (classification, regression)   \n",
       "3          (logistic, r, regression)   \n",
       "4         (distributions, selfstudy)   \n",
       "5        (distributions, timeseries)   \n",
       "6             (logistic, regression)   \n",
       "7      (machinelearning, regression)   \n",
       "8                    (r, regression)   \n",
       "9           (regression, timeseries)   \n",
       "\n",
       "                                          prediction  \n",
       "0                             (logistic, regression)  \n",
       "1                            (regression, selfstudy)  \n",
       "2                  (classification, machinelearning)  \n",
       "3                             (logistic, regression)  \n",
       "4            (distributions, probability, selfstudy)  \n",
       "5                   (machinelearning, r, regression)  \n",
       "6                             (logistic, regression)  \n",
       "7  (classification, logistic, machinelearning, re...  \n",
       "8                           (probability, selfstudy)  \n",
       "9                        (r, regression, timeseries)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict labels\n",
    "y_pred = mlb.inverse_transform(np.array(y_pred_seq))\n",
    "y_true = mlb.inverse_transform(np.array(y_val))\n",
    "\n",
    "df_out = pd.DataFrame({\n",
    "    \"comment\": X_val,\n",
    "    \"actual\": y_true,\n",
    "    \"prediction\": y_pred\n",
    "})\n",
    "display(df_out.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now define a function that does all above\n",
    "# predict tags based on a comment\n",
    "def predict_tag(comment):\n",
    "    text = []\n",
    "    # preprocess\n",
    "    text = [cleaner(text)]\n",
    "    # convert to integer sequences\n",
    "    seq = x_tokenizer.texts_to_sequences(text)\n",
    "    # pad\n",
    "    pad_seq = pad_sequences(seq, padding='post', maxlen=max_len)\n",
    "    # make preds\n",
    "    pred_prob = model.predict(pad_seq)\n",
    "    classes = classify(pred_prob, opt)[0]\n",
    "    classes = np.array(classes)\n",
    "    classes = mlb.inverse_transform(classes)\n",
    "\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
